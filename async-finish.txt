[[ch:async-finish]]
== Chapter: Async-finish parallelism

The "async-finish" approach offers another mechanism for structured
parallelism.  It is similar to fork-join parallelism but is more
flexible, because it allows essentially any number of parallel
branches to synchronize at the same point called a "finish".  Each
"async" creates a separate parallel branch, which by construction must
signal a "finish."

As with fork-join, it is often possible to extend an existing language
with support for async-finish parallelism by providing libraries or
compiler extensions that support a few simple primitives.  Such
extensions to a language make it easy to derive a sequential program
from a parallel program by syntactically substituting the parallelism
annotations with corresponding serial annotations.  This in turn
enables reasoning about the semantics or the meaning of parallel
programs by essentially "ignoring" parallelism, e.g., via the
sequential elision mechanism.


=== Parallel Fibonacci via Async-Finish

Recall that the latexmath:[$n^{th}$] Fibonnacci number is defined
by the recurrence relation

[latexmath]
++++
$$
\begin{array}{lcl}
F(n) & = & F(n-1) + F(n-2)
\end{array}
$$
++++

with base cases

[latexmath]
++++
$$
F(0) = 0, \, F(1) = 1
$$
++++

To write a parallel version, we remark that the two recursive calls
are completely *_independent_*: they do not depend on each other
(neither uses a piece of data generated or written by another).  We
can therefore perform the recursive calls in parallel.  In general,
any two independent functions can be run in parallel.  To indicate
that two functions can be run in parallel, we use `async()`.  It is a
requirement that each `async` takes place in the context of a
`finish`.  All `async`'ed computations that takes place in the context
of a `finish` synchronize at that `finish`, i.e., `finish` completes
only when all the `async`'ed computations complete.  The important
point about a `finish` is that it can serve as the synchronization
point for an arbitrary number of `async`'ed computations.  This is not
quite useful in Fibonacci because there are only two computations to
synchronize at a time, but  it will be useful in our next example.

[source, {cpp}]
----
long fib_par(long n, long &result) {
  if (n < 2) {
    *result = n;
  } else {
    long a, b;
    finish {
      async [&] fib_par(n-1, a);
      aysnc [&] fib_par(n-2, b);
    });
    *result = *a + *b;
  }
}
----

=== Incrementing an array, in parallel

Recall our example for mapping an array to another by incrementing
each element by one.  We can write the code for a function `map_incr`
that performs this computation serially.

[source,{cpp}]
----
void map_incr(const long* source, long* dest, long n) {
  for (long i = 0; i < n; i++)
    dest[i] = source[i] + 1;
}
----

Using async-finish, we can write to code parallel array increment by
using only a single `finish` block and `async`' ing all the parallel
computations inside that `finish`.

[source,{cpp}]
----
void map_incr_rec_aux (const long* source, long* dest, long lo, long hi) {
  long n = hi - lo;
  if (n == 0) {
    // do nothing
  } else if (n == 1) {
    dest[lo] = source[lo] + 1;
  } else {
    long mid = (lo + hi) / 2;
    async ([&] {
      map_incr_rec_aux(source, dest, lo, mid);
    };
    async [&] {
      map_incr_rec_aux(source, dest, mid, hi);
    };
  }
}


void map_incr_rec (const long* source, long* dest, long lo, long hi) {

  finish ([&] { 
    map_inc_rec_aux (source, dest, lo, hi));
  };
} 

----

It is helpful to compare this to fork-join, where we had to
synchronize parallel branches in pairs.  Here, we are able to
synchronize them all at a single point.


Nevertheless, this change does not alter the work and span of the
computation, which remain as latexmath:[O(n)] work and
latexmath:[$O(\log{n})$] span.
